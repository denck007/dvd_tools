{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename ripped dvd tracks with correct season-episode paring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import difflib\n",
    "from glob import glob\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import torch\n",
    "import requests\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_ROOT = \"/mnt/storage/Series/\"\n",
    "AUDIO_ROOT = \"/home/neil/temp/mkv_audio\"\n",
    "subtitles_file = \"/mnt/storage/Series/subitles.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the intro subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Manually set the url for the correct series\")\n",
    "print(f\"Manually set the range end value to make sure to get all the pages.\")\n",
    "requests_end_idx = 175\n",
    "series_url_root = \"https://transcripts.foreverdreaming.org/viewforum.php?f=-1\"\n",
    "\n",
    "results = []\n",
    "completed = set()\n",
    "for offset in range(0,requests_end_idx,25):\n",
    "    done = False\n",
    "    r = requests.get(f\"{series_url_root}&start={offset}\")\n",
    "    soup = bs(r.text)\n",
    "    for item in soup.find_all(\"h3\"):\n",
    "        title = item.text\n",
    "        if title[:2].isnumeric():\n",
    "            title_split  = title.split(\" - \")\n",
    "            ep = title_split[0]\n",
    "            name = \" - \".join(title_split[1:])\n",
    "            ep = ep.replace(\"x\",\"E\").replace(\"/\",\"&\")\n",
    "            print(f\"S{ep} {name}\")\n",
    "            if ep in completed:\n",
    "                done=True\n",
    "                break\n",
    "            results.append(\n",
    "                {\n",
    "                    \"se\": \"S\" + ep,\n",
    "                    \"title\": name,\n",
    "                    \"text\": item.contents[0].attrs['title'].strip('.'),\n",
    "                }\n",
    "            )\n",
    "    if done:\n",
    "        break\n",
    "    time.sleep(1) # rate limit it\n",
    "\n",
    "with open(subtitles_file, 'w') as fp:\n",
    "    json.dump(results, fp, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all the videos and extract the first 15 seconds of audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoAudio:\n",
    "    text = None\n",
    "    text_clean = None\n",
    "\n",
    "    def __init__(self, video_file, audio_temp_dir = AUDIO_ROOT):\n",
    "        self.video = video_file\n",
    "        self.audio = os.path.join(audio_temp_dir, base64.b32encode(hashlib.sha256(self.video.encode()).digest()).decode() + \".wav\")\n",
    "        self.canidates = []\n",
    "\n",
    "        self.create_audio()\n",
    "\n",
    "    def create_audio(self):\n",
    "        if not os.path.isfile(self.audio):\n",
    "            os.system(f'ffmpeg -i \"{self.video}\" -t 00:00:15.0 -ac 1 \"{self.audio}\"')\n",
    "\n",
    "    def set_text(self, text):\n",
    "        self.text = text\n",
    "        self.clean_text = text.lower()\n",
    "        for to_replace in [\"'\", '\"', \",\", \".\", \"-\", \"!\", \"?\"]:\n",
    "            self.clean_text = self.clean_text.replace(to_replace, \"\")\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"video\": self.video,\n",
    "            \"audio\": self.audio,\n",
    "            \"text\": self.text,\n",
    "            \"clean_text\": self.clean_text,\n",
    "            \"canidates\": self.canidates,\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = []\n",
    "for root, _, fnames in os.walk(VIDEO_ROOT):\n",
    "    print(root)\n",
    "    for fname in fnames:\n",
    "        print(fname)\n",
    "        if \"bonus\" in fname.lower():\n",
    "            continue\n",
    "        if fname[5] != \"_\":\n",
    "            print(\"underscore\")\n",
    "            continue\n",
    "        if os.path.splitext(fname)[-1] != \".mkv\":\n",
    "            continue\n",
    "\n",
    "        file_in = os.path.join(root, fname)\n",
    "        print(file_in)\n",
    "        f = VideoAudio(file_in, audio_temp_dir=AUDIO_ROOT)\n",
    "        videos.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run audio to text model over start of video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')  # gpu also works, but our models are fast enough for CPU\n",
    "\n",
    "model, decoder, utils = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                       model='silero_stt',\n",
    "                                       language='en', # also available 'de', 'es'\n",
    "                                       device=device)\n",
    "                                       \n",
    "(read_batch, split_into_batches,\n",
    " read_audio, prepare_model_input) = utils  # see function signature for details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in videos:\n",
    "    if video.text_clean is not None:\n",
    "        continue\n",
    "    data_input = prepare_model_input(read_batch([video.audio]), device=device)\n",
    "    output = model(data_input)\n",
    "    text = decoder(output[0].cpu())\n",
    "    video.set_text(text)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the subtitles, this helps the matcher\n",
    "with open(subtitles_file, 'r') as fp:\n",
    "    labels = json.load(fp)\n",
    "\n",
    "for item in labels:\n",
    "    t = item[\"text\"].lower().strip()\n",
    "    for to_replace in [\"'\", '\"', \",\", \".\", \"-\", \"!\", \"?\"]:\n",
    "        t = t.replace(to_replace, \"\")\n",
    "    \n",
    "    item[\"text\"] = t\n",
    "print(f\"{len(labels)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the python builtin sequence matcher\n",
    "\n",
    "for video in videos:\n",
    "    # Remove exsiting matches before re-matching\n",
    "    video.canidates = []\n",
    "\n",
    "    for idx_l, l in enumerate(labels):\n",
    "        target = l[\"text\"]\n",
    "        length = min(len(target), len(video.clean_text))\n",
    "        sim = difflib.SequenceMatcher(None, video.clean_text[:length], target[:length]).ratio()\n",
    "        if sim > 0.5:\n",
    "            video.canidates.append({**dict(l), \"sim\": sim})\n",
    "    \n",
    "    video.canidates.sort(key=lambda x: x[\"sim\"], reverse=True)\n",
    "    print(f\"{video.video}\")\n",
    "    for canidate in video.canidates:\n",
    "        print(f\"\\t{' '*7}{video.text}\")\n",
    "        print(f\"\\t{canidate['se']:6s}-{canidate['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate strong video canidates for an episode\n",
    "from collections import defaultdict\n",
    "used = defaultdict(list)\n",
    "for video in videos:\n",
    "    if (len(video.canidates) == 1):\n",
    "        if video.canidates[0]['se'] in used:\n",
    "            print(f\"Found duplicate se {video.canidates[0]['se']} for video {video.video}\")\n",
    "        used[video.canidates[0]['se']].append(video.video)\n",
    "\n",
    "for key, val in used.items():\n",
    "    if len(val) <= 1:\n",
    "        continue\n",
    "    print(f\"\\n{key}\")\n",
    "    for v in val:\n",
    "        print(f\"\\t{v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move all videos that have exactly 1 strong match\n",
    "for video in videos:\n",
    "    if (len(video.canidates) == 1) and (video.canidates[0]['sim'] > 0.7):\n",
    "        fname_new = os.path.join(os.path.dirname(video.video), f\"{video.canidates[0]['se']} {video.canidates[0]['title']}{os.path.splitext(video.video)[-1]}\")\n",
    "        if not os.path.isfile(video.video):\n",
    "            print(f\"Source file not found for {video.video} -> {fname_new}\")\n",
    "            continue\n",
    "        elif os.path.isfile(fname_new):\n",
    "            print(f\"Destination file already exists for {video.video} -> {fname_new}\")\n",
    "            continue\n",
    "        shutil.move(video.video, fname_new)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbb42c4979c6fa6ad3e2394573b3170e9ca5b3a92bc7f122b4ab4cd0cd42abba"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 ('movies')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
